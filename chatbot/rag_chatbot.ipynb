{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain\n",
    "import tiktoken\n",
    "import langchain_experimental\n",
    "\n",
    "# Prompt the user for their OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "# Set the API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "txt_file_path = 'military_dataset.csv'\n",
    "loader = TextLoader(file_path=txt_file_path, encoding=\"utf-8\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/77994079/no-module-named-pwd-while-use-from-langchain-community-document-loaders-impor\n",
    "\n",
    "pwd module 문제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "data = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lala5\\AppData\\Local\\Temp\\ipykernel_28140\\980090448.py\", line 5, in <module>\n",
      "    vectorstore = FAISS.from_documents(data, embedding=embeddings)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\langchain_core\\vectorstores.py\", line 508, in from_documents\n",
      "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\", line 965, in from_texts\n",
      "    embeddings = embedding.embed_documents(texts)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 480, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 323, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\resources\\embeddings.py\", line 105, in create\n",
      "    continue\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 1055, in post\n",
      "    cast_to=extract_response_type(response_cls),\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 834, in request\n",
      "    def _prepare_request(\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 865, in _request\n",
      "    ) -> ResponseT:\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 925, in _retry_request\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 865, in _request\n",
      "    ) -> ResponseT:\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 925, in _retry_request\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 877, in _request\n",
      "    ) -> ResponseT | _StreamT:\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Request too large for text-embedding-ada-002 in organization org-KHEem5rOas7LTMSWAHxKXtCO on tokens per min (TPM): Limit 1000000, Requested 2715633. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\lala5\\anaconda3\\envs\\test\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(data, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4\", \n",
    "                 openai_api_key=\"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\", \n",
    "                 openai_organization=\"org-e3djfw9Vuf0b33C9eDUFgPms\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationalRetrievalChain\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
